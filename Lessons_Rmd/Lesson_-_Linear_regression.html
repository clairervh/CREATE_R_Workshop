<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Linear regression</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script src="libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Linear regression</h1>

</div>


<hr />
<ul>
<li><a href="#motivation">What, and why?</a><br />
</li>
<li><a href="#simplelm">Simple linear regression</a>
<ul>
<li><a href="#lookAt">Look at your data!</a></li>
<li><a href="#fitModel">Running a linear regression</a></li>
<li><a href="#checkAssumptions">Check model assumptions</a></li>
<li><a href="#extractStatistics">Extracting summary statistics</a></li>
<li><em><a href="#challengelm">Challenge</a></em></li>
<li><a href="#lookAtlm">Looking at your regression</a></li>
</ul></li>
<li><a href="#multipleRegression">Multiple regression</a>
<ul>
<li><a href="#lookAt2">Look at your data!</a></li>
<li><a href="#fitModel2">Fit the model</a></li>
<li><a href="#checkAssumptions2">Check model assumptions</a><br />
</li>
</ul></li>
<li><a href="#resources">Resources</a></li>
</ul>
<hr />
<div id="motivation" class="section level1">
<h1>Why, and what?</h1>
<p>Linear regression is a useful statistical technique that allows us to explore the relationship between a dependent variable of interest (also known as the response variable) and other, independent variables (also known as explanatory variables).</p>
<p>R has functions in the base statistics package that allow us to implement simple (and multiple) linear regression. There are also other packages that include functions for linear regression as the simple form of more complex analyses, such as linear mixed models - for example, see <a href="https://cran.r-project.org/web/packages/nlme/index.html"><code>nlme</code></a> and <a href="https://cran.r-project.org/package=lme4"><code>lme4</code></a>. In this lesson, we will stick to linear regression in the base package.</p>
</div>
<div id="simplelm" class="section level1">
<h1>Simple linear regression</h1>
<p>Let’s start by considering a case where we want to look at the relationship between one response variable and one explanatory variable. With one explanatory variable, this is called simple linear regression.</p>
<p>The equation that describes this relationship is as follows, where x is the explanatory variable and y is the response variable:</p>
<center>
y = <span class="math inline">\(\alpha\)</span> + <span class="math inline">\(\beta\)</span>x + <span class="math inline">\(\epsilon\)</span>
</center>
<p><br> <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are called parameters, where <span class="math inline">\(\alpha\)</span> gives the intercept and <span class="math inline">\(\beta\)</span> gives the slope, and <span class="math inline">\(\epsilon\)</span> is the error term.</p>
<p>Simple linear regression estimates the relationship between x and y by fitting a straight line through the data points. The residuals are calculated as the differences between the modeled and measured values of the dependent variables for each value of the independent variable. To fit the model, linear regression uses the method of least squares, meaning that the sum of the squared residuals is minimized.</p>
<p>We’ll run a simple linear regression using the <code>Inverts</code> data. Read in the data if it’s not already in your environment:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in Inverts data (first introduced in functions lesson)</span>
Inverts &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="dt">file=</span><span class="st">&quot;Data/Inverts.csv&quot;</span>, <span class="dt">stringsAsFactors=</span><span class="ot">TRUE</span>, <span class="dt">header=</span><span class="ot">TRUE</span>)</code></pre></div>
<div id="lookAt" class="section level2">
<h2>Look at your data!</h2>
<p>If you’re interested in the relationship between two variables, the first step should always be to look at the data. This is important because it is possible for pairs of vectors with very different relationships to each other to have exactly the same summary statistics. An example of this is <a href="https://en.wikipedia.org/wiki/Anscombe%27s_quartet">Anscombe’s quartet</a>, constructed by the statistician Francis Anscombe in 1973. Each of these data sets has the same mean for x, the same mean for y (to 2 decimal places), the same correlation between x and y (to 3 decimal places) and the same linear regression (to 2 decimal places for the intercept and 3 for the slope).</p>
<p><img src="Images/LMImages/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /></p>
<p>Despite the similarities in summary statistics, it is clear that blindly implementing simple linear regression would be a very poor choice! Linear regression does a good job of describing the relationship between x and y for (a), but not for (b) and (d), and in (c), a single outlier leads to a less appropriate linear regression fit. (For underlying data, see <code>anscombe</code>.)</p>
<p>In conclusion: <em>plot your data!</em></p>
<p>Let’s look at the relationship between richness and TOC in the Inverts dataset. We will start with a scatterplot of the two variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(Richness ~<span class="st"> </span>TOC, <span class="dt">data=</span>Inverts, <span class="dt">pch=</span><span class="dv">19</span>, <span class="dt">las=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="Images/LMImages/unnamed-chunk-5-1.png" width="500pt" style="display: block; margin: auto;" /></p>
<p>It looks like a linear regression would be a reasonable approach for this data set.</p>
</div>
<div id="fitModel" class="section level2">
<h2>Running a linear regression</h2>
<p>For linear regression in R, we use the function <code>lm</code>. We call the function, and assign the resulting model to a variable, using this general syntax (where the data are in a data frame called <code>dataset</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Linear regression of y variable versus x variable</span>
    model &lt;-<span class="st"> </span><span class="kw">lm</span>(dataset$y.variable ~<span class="st"> </span>dataset$x.variable) 

<span class="co"># OR</span>

<span class="co"># Same result, cleaner syntax</span>
    model &lt;-<span class="st"> </span><span class="kw">lm</span>(y.variable ~<span class="st"> </span>x.variable, <span class="dt">data=</span>dataset) </code></pre></div>
<p>So, for the Inverts data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Inverts.lm &lt;-<span class="st"> </span><span class="kw">lm</span>(Richness ~<span class="st"> </span>TOC, <span class="dt">data =</span> Inverts)</code></pre></div>
<p>Looking at the model object will give us the information about the coefficients - i.e., the intercept and the slope of the model - along with the original model formula.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Inverts.lm</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Richness ~ TOC, data = Inverts)
## 
## Coefficients:
## (Intercept)          TOC  
##       16.91        58.25</code></pre>
<p>To get more information about the linear regression, we can use the <code>summary</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Inverts.lm)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Richness ~ TOC, data = Inverts)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.3934 -1.2998 -0.4218  1.6808  5.2575 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   16.915      1.969   8.592 1.77e-08 ***
## TOC           58.255      2.222  26.217  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.39 on 22 degrees of freedom
## Multiple R-squared:  0.969,  Adjusted R-squared:  0.9676 
## F-statistic: 687.3 on 1 and 22 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Take a look at the <code>Coefficients</code> section of the output. The <code>Estimate</code> column tells us the intercept of the regression, as well as the slope of the relationship of Richness with TOC. The standard errors of these estimates is given in the next column over, <code>Std. Error</code>. The last column, <code>Pr(&gt;|t|)</code>, gives us the p-values. A p-value indicates significance by indicating the likelihood of your data given the null hypothesis (that the coefficients have values equal to 0). Specifically, it is the probability of finding the observed (or a “more extreme”) result if, in fact, the null hypothesis is correct. These p-values are based on the t-statistic given in the <code>t value</code> column.</p>
<p>From the p-values (and the asterisks next to them), we can see that both the intercept and the slope are significant, the latter indicating that richness is significantly dependent on total organic carbon.</p>
<p>You may also be interested in the adjusted r<sup>2</sup> value, the F-statistic, and the p-value for the overall model - which, in simple linear regression, is the same as for the independent variable. These can be found in the last 2 lines of the output. The adj. r<sup>2</sup> suggests that most of the variability in richness is explained by variation in TOC - such a high r<sup>2</sup> is rare for ecological data! (Making up fake data is great, eh?)</p>
<p>You could obtain the same information by piping the output of the model to <code>summary</code>, without saving the model first. However, saving the model can be useful for looking at other aspects of it. For example, once the model is fit, it’s important to take a look at the residuals to decide whether the regression model is a good one for this data.</p>
</div>
<div id="checkAssumptions" class="section level2">
<h2>Check model assumptions</h2>
<p>To assess the residuals, we will look at a plot of the residuals against the fitted values, to see if there are any apparent patterns. We can access the residuals using <code>resid(Inverts.lm)</code>, and the fitted values using <code>fitted(Inverts.lm)</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">resid</span>(Inverts.lm) ~<span class="st"> </span><span class="kw">fitted</span>(Inverts.lm), <span class="dt">xlab=</span><span class="st">&quot;Fitted values&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Residuals&quot;</span>)</code></pre></div>
<p><img src="Images/LMImages/unnamed-chunk-10-1.png" width="500pt" style="display: block; margin: auto;" /></p>
<p>Fortunately, it doesn’t look like the residuals are dependent on the fitted values.</p>
<p>Now we’ll check the normality of the residuals. We can do that in two ways: first, through a histogram of the residuals, and second, with a QQ plot (more below). Remember that it is the residuals that need to be normal, not the underlying data!</p>
<p>We use the function <code>hist</code> to make a histogram of the residuals. The groupings are calculated by default, but you can change this with the argument <code>breaks</code> if you’d like.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(<span class="kw">resid</span>(Inverts.lm), <span class="dt">xlab =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Histogram of residuals of Inverts.lm&quot;</span>)</code></pre></div>
<p><img src="Images/LMImages/unnamed-chunk-11-1.png" width="500pt" style="display: block; margin: auto;" /></p>
<p>The distribution of values looks relatively normal. There might be a slight skew, but given the relatively small sample size, the histogram does not give us evidence to reject normality.</p>
<p>Now we’ll plot a QQ plot. A QQ plot compares the distribution of two given sets of data by plotting quantiles against each other, hence the Qs in QQ plot. With the <code>qqnorm</code> function, the input vector (here, the residuals of our linear regression model) is compared against normally distributed data. To do this, both data sets are sorted and then plotted against each other. If the input data set is normal, the points should fall along the line where x equals y. The function <code>qqline</code> plots that line, to make it easier to assess the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(<span class="kw">resid</span>(Inverts.lm)) 
<span class="kw">qqline</span>(<span class="kw">resid</span>(Inverts.lm))</code></pre></div>
<p><img src="Images/LMImages/unnamed-chunk-12-1.png" width="500pt" style="display: block; margin: auto;" /></p>
<p>When the data do not fall on the line, the shape of their curve can tell you about the distribution of the data. In our case, the QQ plot indicates that the residuals are normally distributed.</p>
</div>
<div id="extractStatistics" class="section level2">
<h2>Extracting summary statistics</h2>
<p>If you’re working with lots of linear regressions at once, e.g. if you are calculating rates for a linear process for many samples, it can be helpful to automatically extract summary statistics on the linear regression. Some of these are easier to extract than others. Let’s take another look at the model summary output, along with the attributes of the model summary, using the function <code>attributes</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Inverts.lm)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Richness ~ TOC, data = Inverts)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.3934 -1.2998 -0.4218  1.6808  5.2575 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   16.915      1.969   8.592 1.77e-08 ***
## TOC           58.255      2.222  26.217  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.39 on 22 degrees of freedom
## Multiple R-squared:  0.969,  Adjusted R-squared:  0.9676 
## F-statistic: 687.3 on 1 and 22 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attributes</span>(<span class="kw">summary</span>(Inverts.lm))</code></pre></div>
<pre><code>## $names
##  [1] &quot;call&quot;          &quot;terms&quot;         &quot;residuals&quot;     &quot;coefficients&quot; 
##  [5] &quot;aliased&quot;       &quot;sigma&quot;         &quot;df&quot;            &quot;r.squared&quot;    
##  [9] &quot;adj.r.squared&quot; &quot;fstatistic&quot;    &quot;cov.unscaled&quot; 
## 
## $class
## [1] &quot;summary.lm&quot;</code></pre>
<p>We can access the different attributes by name from the summary object. For example, let’s look at the adjusted r<sup>2</sup>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Inverts.lm)$adj.r.squared</code></pre></div>
<pre><code>## [1] 0.9675749</code></pre>
<p>Pulling out the regression equation and the p-value of the model take a few more steps. All of the values are in the <code>coefficients</code> table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Inverts.lm)$coefficients</code></pre></div>
<pre><code>##             Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept) 16.91482   1.968642  8.592123 1.768433e-08
## TOC         58.25458   2.222021 26.216936 4.359055e-18</code></pre>
<p>To pull out a particular value, you could access it by specifying its position in the table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Get p-value for TOC, which is in the 2nd row and 4th column</span>
<span class="kw">summary</span>(Inverts.lm)$coefficients[<span class="dv">2</span>, <span class="dv">4</span>]</code></pre></div>
<pre><code>## [1] 4.359055e-18</code></pre>
<p>Alternatively, you can specify the names of the rows and columns.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Get p-value for TOC using row and column names</span>
<span class="kw">summary</span>(Inverts.lm)$coefficients[<span class="st">&quot;TOC&quot;</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</code></pre></div>
<pre><code>## [1] 4.359055e-18</code></pre>
<p>For simple regression, the t-value and p-value for the linear fit between the two variables are the same as the t-value and p-value of the correlation between the two variables. Thus, you could also get the p-value by running a Pearson’s correlation, which you can do using the function <code>cor.test</code> with the method set to <code>&quot;pearson&quot;</code>. You can then extract the p-value from this test. For <code>cor.test</code>, you can specify the <code>x</code> and <code>y</code> vectors, or you can pass it a formula.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Pearson&#39;s correlation between TOC and Richness</span>
    <span class="co"># Using individual vectors, you could run this as:</span>
    <span class="co">#   cor.test(Inverts$TOC, Inverts$Richness)</span>
    <span class="co"># Another option is to specify a formula</span>
        <span class="kw">cor.test</span>(~<span class="st"> </span>Richness +<span class="st"> </span>TOC, <span class="dt">data=</span>Inverts)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  Richness and TOC
## t = 26.217, df = 22, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.9636184 0.9933256
## sample estimates:
##       cor 
## 0.9843702</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Look at names of attributes </span>
    <span class="kw">attributes</span>(<span class="kw">cor.test</span>(~<span class="st"> </span>Richness +<span class="st"> </span>TOC, <span class="dt">data=</span>Inverts))</code></pre></div>
<pre><code>## $names
## [1] &quot;statistic&quot;   &quot;parameter&quot;   &quot;p.value&quot;     &quot;estimate&quot;    &quot;null.value&quot; 
## [6] &quot;alternative&quot; &quot;method&quot;      &quot;data.name&quot;   &quot;conf.int&quot;   
## 
## $class
## [1] &quot;htest&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Extract the p.value   </span>
    <span class="kw">cor.test</span>(~<span class="st"> </span>Richness +<span class="st"> </span>TOC, <span class="dt">data=</span>Inverts)$p.value</code></pre></div>
<pre><code>## [1] 4.359055e-18</code></pre>
<div id="challengelm" class="section level4">
<h4>Challenge</h4>
<ol style="list-style-type: decimal">
<li><p>Use a simple linear regression to look at whether species richness is dependent on mean stream temperature in the <code>Inverts</code> data frame.</p></li>
<li><p>Read in the <code>genes.csv</code> data file from the lesson on joining data frames. Examine the relationship between the abundance of nirS and the abundance of nosZ by plotting the data and then fitting a linear regression model. What are the p-value and the adjusted r<sup>2</sup> of the overall model? Is the linear relationship significant?</p></li>
<li><p>Read in the <code>climates.csv</code> data file from the lesson on joining data frames. Examine the relationship between mean annual precipitation (MAP) and mean annual temperature (MAT) by plotting the data and then fitting a linear regression model. What are the p-value and the adjusted r<sup>2</sup> of the overall model? Is the linear relationship significant?</p></li>
<li><p>Extract the slope, intercept, p-value, and adjusted r<sup>2</sup> of the linear regression model of the relationship between MAP and MAT. That is to say, write a line of code that, when run, returns the desired value.</p></li>
<li><p>Write a function that returns a vector with the slope and intercept of a simple linear regression model. Test your function with the model that you created in the previous challenge question.</p></li>
</ol>
</div>
</div>
<div id="lookAtlm" class="section level2">
<h2>Looking at your regression</h2>
<p>Once you’ve run a linear regression, you can plot it on a scatterplot. The simplest way to do this is to use the function <code>abline</code> and give it the model object as input.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(Richness ~<span class="st"> </span>TOC, <span class="dt">data=</span>Inverts, <span class="dt">pch=</span><span class="dv">19</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">1.6</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">120</span>)
         , <span class="dt">axes=</span>F, <span class="dt">ann=</span>F)  <span class="co"># Plot without axes</span>
    <span class="kw">axis</span>(<span class="dv">1</span>, <span class="dt">pos=</span><span class="dv">0</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">1.6</span>, <span class="dt">by=</span><span class="fl">0.4</span>), <span class="dt">cex.axis=</span><span class="fl">1.2</span>)  <span class="co"># Add x-axis; place it at y = 0</span>
        <span class="kw">mtext</span>(<span class="dt">side=</span><span class="dv">1</span>, <span class="dt">line=</span><span class="dv">2</span>, <span class="dt">text=</span><span class="st">&quot;Total organic carbon (%)&quot;</span>, <span class="dt">cex=</span><span class="fl">1.2</span>)
    <span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">pos=</span><span class="dv">0</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">cex.axis=</span><span class="fl">1.2</span>)  <span class="co"># Add y-axis; place it at x = 0</span>
        <span class="kw">mtext</span>(<span class="dt">side=</span><span class="dv">2</span>, <span class="dt">line=</span><span class="dv">2</span>, <span class="dt">text=</span><span class="st">&quot;Species richness&quot;</span>, <span class="dt">cex=</span><span class="fl">1.2</span>)
<span class="kw">abline</span>(Inverts.lm) <span class="co"># Plot linear regression</span></code></pre></div>
<p><img src="Images/LMImages/unnamed-chunk-24-1.png" width="500pt" style="display: block; margin: auto;" /></p>
<p>However, you can see that the line extends to the end of the plot margins, which can look awkward if you’ve specified the placement of your axes. An alternative approach is to draw a line with x and y coordinates of your choosing. For this plot, we might want to use x = 0.3 and 1.4. To calculate the appropriate y-values, we can use the <code>predict</code> function. This function uses the linear regression to calculate modeled values for the response variable based on the selected values for the explanatory variable. Once we have the y values, we can use the function <code>lines</code> to draw a line with specified x and y coordinates. We can use many of the same <code>par</code> arguments for <code>lines</code> as we can with <code>points</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(Richness ~<span class="st"> </span>TOC, <span class="dt">data=</span>Inverts, <span class="dt">pch=</span><span class="dv">19</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">1.6</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">120</span>)
         , <span class="dt">axes=</span>F, <span class="dt">ann=</span>F)  <span class="co"># Plot without axes</span>
    <span class="kw">axis</span>(<span class="dv">1</span>, <span class="dt">pos=</span><span class="dv">0</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">1.6</span>, <span class="dt">by=</span><span class="fl">0.4</span>), <span class="dt">cex.axis=</span><span class="fl">1.2</span>)  <span class="co"># Add x-axis; place it at y = 0</span>
        <span class="kw">mtext</span>(<span class="dt">side=</span><span class="dv">1</span>, <span class="dt">line=</span><span class="dv">2</span>, <span class="dt">text=</span><span class="st">&quot;Total organic carbon (%)&quot;</span>, <span class="dt">cex=</span><span class="fl">1.2</span>)
    <span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">pos=</span><span class="dv">0</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">cex.axis=</span><span class="fl">1.2</span>)  <span class="co"># Add y-axis; place it at x = 0</span>
        <span class="kw">mtext</span>(<span class="dt">side=</span><span class="dv">2</span>, <span class="dt">line=</span><span class="dv">2</span>, <span class="dt">text=</span><span class="st">&quot;Species richness&quot;</span>, <span class="dt">cex=</span><span class="fl">1.2</span>)

<span class="co"># Calculate y values given specified x values, then plot x and y values</span>
yvals &lt;-<span class="st"> </span><span class="kw">predict</span>(Inverts.lm, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">TOC =</span> <span class="kw">c</span>(<span class="fl">0.3</span>, <span class="fl">1.4</span>)))
<span class="kw">lines</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="fl">0.3</span>, <span class="fl">1.4</span>), <span class="dt">y =</span> yvals, <span class="dt">col=</span><span class="st">&quot;mediumorchid&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="Images/LMImages/unnamed-chunk-25-1.png" width="500pt" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="multipleRegression" class="section level1">
<h1>Multiple regression</h1>
<p>Simple linear regression can be extended to include multiple explanatory variables. For example, is species richness related to the variability in current speed, as well as to organic carbon?</p>
<div id="lookAt2" class="section level2">
<h2>Look at your data!!</h2>
<p>Again, it’s a good idea to look at your data! Let’s look at the relationship between species richness and current variability. (We won’t go into 3-dimensional graphs to look at all 3 variables.)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(Richness ~<span class="st"> </span>CurrentVariability, <span class="dt">data=</span>Inverts, <span class="dt">pch=</span><span class="dv">19</span>, <span class="dt">las=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="Images/LMImages/unnamed-chunk-26-1.png" width="500pt" style="display: block; margin: auto;" /></p>
<p>It really doesn’t look like there’s a relationship between these two variables, does it - linear or otherwise. Nonetheless, we’ll proceed with a multiple regression model, to demonstrate the process.</p>
</div>
<div id="fitModel2" class="section level2">
<h2>Fit the model</h2>
<p>To do a multiple linear regression, we add variables to the formula in the <code>lm</code> function. As an example, let’s look at the relationship between the response variable <code>Richness</code> and the explanatory variables <code>TOC</code> and <code>CurrentVariability</code>. As with simple regression, we can look at the model with <code>summary</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Inverts2.lm &lt;-<span class="st"> </span><span class="kw">lm</span>(Richness ~<span class="st"> </span>TOC +<span class="st"> </span>CurrentVariability, <span class="dt">data=</span>Inverts)
<span class="kw">summary</span>(Inverts2.lm)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Richness ~ TOC + CurrentVariability, data = Inverts)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9756 -1.7563  0.3645  1.9718  3.9323 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        20.97942    3.17648   6.605 1.54e-06 ***
## TOC                58.23833    2.14752  27.119  &lt; 2e-16 ***
## CurrentVariability -0.09649    0.06038  -1.598    0.125    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.31 on 21 degrees of freedom
## Multiple R-squared:  0.9723, Adjusted R-squared:  0.9697 
## F-statistic: 369.2 on 2 and 21 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The output suggests that species richness is significantly dependent on total organic carbon but not variability in current speed, and adding current speed to the model is not necessary for explaining variability in species richness.</p>
<p>If we replaced the <code>+</code> with <code>*</code>, the model would include both explanatory variables and their interaction. Just the interaction can be specified with <code>:</code>, as in <code>TOC:CurrentVariability</code>. So, both of these calls would include both explanatory variables (main effects) as well as their interaction:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Specify main effects and interaction with one operator</span>
    <span class="kw">lm</span>(Richness ~<span class="st"> </span>TOC *<span class="st"> </span>CurrentVariability, <span class="dt">data=</span>Inverts)  

<span class="co"># Specify main effects separately from the interaction</span>
    <span class="kw">lm</span>(Richness ~<span class="st"> </span>TOC +<span class="st"> </span>CurrentVariability +<span class="st"> </span>TOC:CurrentVariability)  </code></pre></div>
<p>Let’s go back to the original model. If you want to do an F-test and compare F-values rather than t-values, you can use the <code>drop1</code> function, which looks at the effect on the entire model of adding the specified variable last. This will be more important in the next lesson on ANOVA. In short, for a linear regression, you get the same p-values as you do using <code>summary</code>, but <code>drop1</code> lets you pull out the F-values if you need them. In the function call, you give as arguments the original model, an argument specifying the terms to be considered for adding or dropping (<code>.~.</code> for all terms), and the test statistic of interest.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">drop1</span>(Inverts2.lm, .~., <span class="dt">test=</span><span class="st">&quot;F&quot;</span>)</code></pre></div>
<pre><code>## Single term deletions
## 
## Model:
## Richness ~ TOC + CurrentVariability
##                    Df Sum of Sq    RSS     AIC  F value Pr(&gt;F)    
## &lt;none&gt;                           112.0  42.980                    
## TOC                 1    3923.9 4035.9 126.999 735.4341 &lt;2e-16 ***
## CurrentVariability  1      13.6  125.7  43.734   2.5535  0.125    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Of course, to use this model, you should then check that your residuals are normally distributed and not dependent on the explanatory variables!</p>
</div>
<div id="checkAssumptions2" class="section level2">
<h2>Check model assumptions</h2>
<p>We will check the residuals similarly to above, but with our multiple regression model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set plot layout and margins</span>
    <span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">8</span>,<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">2</span>))
<span class="co"># Plot histogram</span>
    <span class="kw">hist</span>(<span class="kw">resid</span>(Inverts2.lm))  
<span class="co"># Make QQ plot to check normality</span>
    <span class="kw">qqnorm</span>(<span class="kw">resid</span>(Inverts2.lm))  
    <span class="kw">qqline</span>(<span class="kw">resid</span>(Inverts2.lm))</code></pre></div>
<p><img src="Images/LMImages/unnamed-chunk-30-1.png" width="600pt" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set plot layout and margins</span>
    <span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">2</span>,<span class="dv">2</span>))  
<span class="co"># Plot residuals against TOC (explanatory variable)</span>
    <span class="kw">plot</span>(Inverts$TOC, <span class="kw">resid</span>(Inverts2.lm), <span class="dt">pch=</span><span class="dv">19</span>, <span class="dt">las=</span><span class="dv">1</span>)  
<span class="co"># Plot residuals against Current Variability (explanatory variable)</span>
    <span class="kw">plot</span>(Inverts$CurrentVariability, <span class="kw">resid</span>(Inverts2.lm), <span class="dt">pch=</span><span class="dv">19</span>, <span class="dt">las=</span><span class="dv">1</span>)
<span class="co"># Plot residuals against fitted values</span>
    <span class="kw">plot</span>(<span class="kw">fitted</span>(Inverts2.lm), <span class="kw">resid</span>(Inverts2.lm), <span class="dt">pch=</span><span class="dv">19</span>, <span class="dt">las=</span><span class="dv">1</span>)  
<span class="co"># Reset plot layout and margins</span>
    <span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">2</span>,<span class="dv">2</span>))  </code></pre></div>
<p><img src="Images/LMImages/unnamed-chunk-30-2.png" width="600pt" style="display: block; margin: auto;" /></p>
<p>The residuals look a little skewed in the histogram, but the QQ plot suggests that they are reasonably normal, and the plots of residuals against fitted values and explanatory variables suggests homogeneity. (Keep in mind that even with normally distributed data, these plots can look a little funny when <em>n</em>, sample size, is low.) So you can safely report your conclusion that species richness is significantly related to organic carbon and not to current variability.</p>
<p>Realistically, though, you’d likely want to drop <code>CurrentVariability</code> from the model, since it is not adding any explanatory power. However, there is much discussion around the process of adding and removing model terms, and we will swiftly move on to ANOVA and not add to the debate!</p>
<hr />
</div>
</div>
<div id="resources" class="section level1">
<h1>Resources</h1>
<p><a href="http://www.r-bloggers.com/simple-linear-regression-2/">R-bloggers on simple linear regression</a></p>
<hr />
<!-- For making and looking at normally distributed fake data:
test <- rnorm(c(1:25), sd=5)+seq(from=30, length.out=25, by=01)
plot(1:25, test, xlim=c(0, 25), ylim=c(0, 60)) -->
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
